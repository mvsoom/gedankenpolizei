<!DOCTYPE html>
<!--
Note: this is a single large HTML file to sidestep CORS issues.
Script is heavily based on three.js examples: https://threejs.org/examples/
-->
<html lang="en">
<head>
    <title>SEER</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
    <style>
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline style="display:none"></video>

    <!-- This shader transforms 2D points from the webcam texture into 3D space. It calculates depth from the texture color and positions each vertex accordingly; also sets the size of each point -->
    <script id="vs" type="x-shader/x-vertex">
        uniform sampler2D map;
        uniform float width;
        uniform float height;
        uniform float nearClipping, farClipping;
        uniform float pointSize;
        uniform float zOffset;
        varying vec2 vUv;
        const float XtoZ = 1.11146;
        const float YtoZ = 0.83359;
        void main() {
            vUv = vec2(position.x / width, position.y / height);
            vec4 color = texture2D(map, vUv);
            float depth = (color.r + color.g + color.b) / 3.0;
            float z = (1.0 - depth) * (farClipping - nearClipping) + nearClipping;
            vec4 pos = vec4(
                (position.x / width - 0.5) * z * XtoZ,
                (position.y / height - 0.5) * z * YtoZ,
                -z + zOffset,
                1.0);
            gl_PointSize = pointSize;
            gl_Position = projectionMatrix * modelViewMatrix * pos;
        }
    </script>

    <!-- This shader colors each point based on the webcam texture -->
    <script id="fs" type="x-shader/x-fragment">
        uniform sampler2D map;
        varying vec2 vUv;
        void main() {
            vec4 color = texture2D(map, vUv);
            gl_FragColor = vec4(color.r, color.g, color.b, 0.2);
        }
    </script>

    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.150.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.150.0/examples/jsm/"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';
        import { GUI } from 'three/addons/libs/lil-gui.module.min.js';

        // ---------------------------------------------------------------------------
        // Settings
        // ---------------------------------------------------------------------------

        // Scene
        const INITIAL_CAMERA_Z = 1500;

        // Webcam stream
        const NEAR_CLIPPING = 2012;
        const FAR_CLIPPING = 4000;
        const Z_OFFSET = 706;
        const POINT_SIZE = 2;

        // Text display
        const TEXT_CANVAS_WIDTH = 600;
        const TEXT_CANVAS_HEIGHT = 480;
        const FONT_SIZE = 20;
        const FONT_FAMILY = 'Arial';
        const TEXT_COLOR = 'rgba(255, 255, 255, 0.7)';
        const LINE_HEIGHT = 24;
        const TEXT_OFFSET = 50;
        const FADE_HEIGHT = 100;
        const MAX_TEXT_WIDTH = TEXT_CANVAS_WIDTH - 40;
        const DISPLAY_CONTROLS = true;

        // Websocket
        const WS_VIDEO_URL = 'ws://localhost:8765';
        const WS_VIDEO_FPS = 100; // msec
        const WS_VIDEO_RETRY = 500; // msec

        const WS_TEXT_URL = 'ws://localhost:8766';
        const WS_TEXT_RETRY = 500; // msec


        let scene, camera, renderer;
        let mouse, center;
        const initialCameraPosition = new THREE.Vector3(0, 0, INITIAL_CAMERA_Z);
        let targetCameraPosition = initialCameraPosition.clone();
        let textMesh;
        const textBuffer = []; // List of text lines

        init();

        // ---------------------------------------------------------------------------
        // Setup scene and websockets
        // ---------------------------------------------------------------------------
        async function init() {
            const container = document.createElement('div');
            document.body.appendChild(container);

            // Setup camera
            camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 1, 10000);
            camera.position.copy(initialCameraPosition);

            scene = new THREE.Scene();
            center = new THREE.Vector3();
            center.z = -1000;

            renderer = new THREE.WebGLRenderer();
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setAnimationLoop(animate);
            container.appendChild(renderer.domElement);

            mouse = new THREE.Vector3(0, 0, 1);

            // Handle user input
            document.addEventListener('mousemove', onDocumentMouseMove);
            document.addEventListener('mouseleave', onDocumentMouseLeave);
            window.addEventListener('resize', onWindowResize);
            document.addEventListener('wheel', onDocumentMouseWheel);
            document.addEventListener('touchstart', onDocumentTouchStart, false);
            document.addEventListener('touchmove', onDocumentTouchMove, false);

            setupWebcam();
            setupTextCanvas();
            connectWebSocketVideo();
            connectWebSocketText();
        }

        function animate() {
            camera.position.lerp(targetCameraPosition, 0.05);
            camera.lookAt(center);
            renderer.render(scene, camera);
        }

        // ---------------------------------------------------------------------------
        // Optional control setup (if DISPLAY_CONTROLS)
        // ---------------------------------------------------------------------------
        function setupGUI(material) {
            const gui = new GUI();
            gui.add(material.uniforms.nearClipping, 'value', 1, 10000, 1.0).name('nearClipping');
            gui.add(material.uniforms.farClipping, 'value', 1, 10000, 1.0).name('farClipping');
            gui.add(material.uniforms.pointSize, 'value', 1, 10, 1.0).name('pointSize');
            gui.add(material.uniforms.zOffset, 'value', 0, 4000, 1.0).name('zOffset');
        }

        // ---------------------------------------------------------------------------
        // Setup webcam stream and transformation to 3D
        // ---------------------------------------------------------------------------
        async function setupWebcam() {
            const video = document.getElementById('video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;

            video.onloadedmetadata = () => {
                // Use video's native width and height
                const nativeWidth = video.videoWidth;
                const nativeHeight = video.videoHeight;

                const texture = new THREE.VideoTexture(video);
                texture.minFilter = THREE.NearestFilter;

                const geometry = new THREE.BufferGeometry();
                const vertices = new Float32Array(nativeWidth * nativeHeight * 3);
                for (let i = 0, j = 0, l = vertices.length; i < l; i += 3, j++) {
                    vertices[i] = j % nativeWidth;
                    vertices[i + 1] = Math.floor(j / nativeWidth);
                }
                geometry.setAttribute('position', new THREE.BufferAttribute(vertices, 3));

                // Rest of the material and mesh setup remains the same
                const material = new THREE.ShaderMaterial({
                    uniforms: {
                        'map': { value: texture },
                        'width': { value: TEXT_CANVAS_WIDTH },
                        'height': { value: TEXT_CANVAS_HEIGHT },
                        'nearClipping': { value: NEAR_CLIPPING },
                        'farClipping': { value: FAR_CLIPPING },
                        'pointSize': { value: POINT_SIZE },
                        'zOffset': { value: Z_OFFSET }
                    },
                    vertexShader: document.getElementById('vs').textContent,
                    fragmentShader: document.getElementById('fs').textContent,
                    blending: THREE.AdditiveBlending,
                    depthTest: false,
                    depthWrite: false,
                    transparent: true
                });

                const mesh = new THREE.Points(geometry, material);
                scene.add(mesh);

                if (DISPLAY_CONTROLS)
                    setupGUI(material);
            };
        }

        // ---------------------------------------------------------------------------
        // Setup text canvas to display incoming text
        // ---------------------------------------------------------------------------
        function setupTextCanvas() {
            const canvas = document.createElement('canvas');
            canvas.width = TEXT_CANVAS_WIDTH;
            canvas.height = TEXT_CANVAS_HEIGHT;
            const context = canvas.getContext('2d');

            const textTexture = new THREE.CanvasTexture(canvas);
            textTexture.needsUpdate = true;

            const textMaterial = new THREE.MeshBasicMaterial({
                map: textTexture,
                transparent: true,
            });
            const textGeometry = new THREE.PlaneGeometry(TEXT_CANVAS_WIDTH, TEXT_CANVAS_HEIGHT);
            textMesh = new THREE.Mesh(textGeometry, textMaterial);
            textMesh.position.set(0, 0, 100);
            scene.add(textMesh);
        }

        // ---------------------------------------------------------------------------
        // Setup retrying websocket for binary MJPEG out stream
        // ---------------------------------------------------------------------------
        function connectWebSocketVideo() {
            const socket = new WebSocket(WS_VIDEO_URL);
            socket.binaryType = 'arraybuffer';

            socket.onopen = () => {
                console.log('WebSocket connection for video opened');
                setInterval(() => sendFrame(socket), WS_VIDEO_FPS);
            };

            socket.onclose = () => {
                console.log('WebSocket connection for video closed, retrying...');
                setTimeout(connectWebSocketVideo, WS_VIDEO_RETRY);
            };

            socket.onerror = (error) => {
                console.log('WebSocket video error:', error);
                socket.close();
            };
        }

        // Send video frame through WebSocket
        function sendFrame(socket) {
            const video = document.getElementById('video');
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const context = canvas.getContext('2d');
            context.drawImage(video, 0, 0, canvas.width, canvas.height);

            canvas.toBlob((blob) => {
                if (socket && socket.readyState === WebSocket.OPEN) {
                    blob.arrayBuffer().then(buffer => {
                        socket.send(buffer);
                    });
                    console.log('Sent video frame');
                }
            }, 'image/jpeg');
        }

        // ---------------------------------------------------------------------------
        // Setup retrying websocket for binary text in stream
        // ---------------------------------------------------------------------------
        function connectWebSocketText() {
            const socket = new WebSocket(WS_TEXT_URL);
            socket.binaryType = 'arraybuffer';

            socket.onopen = () => {
                console.log('WebSocket connection for text opened');
            };

            // Decode incoming text messages from possibly incomplete binary UTF-8 chunks
            const decoder = new TextDecoder('utf-8', { stream: true });

            socket.onmessage = (event) => {
                const text = decoder.decode(event.data, { stream: true });
                console.log('Received message:', text);
                if (text) {
                    // Add text chunk to textBuffer (a list of lines)
                    const lines = text.split('\n');
                    lines.forEach((line, index) => {
                        if (index === 0) {
                            if (textBuffer.length > 0) {
                                textBuffer[textBuffer.length - 1] += line;
                            } else {
                                textBuffer.push(line);
                            }
                        } else {
                            textBuffer.push(line);
                        }
                    });
                    updateTextCanvas();
                }
            };

            socket.onclose = () => {
                console.log('WebSocket connection for text closed, retrying...');
                setTimeout(connectWebSocketText, WS_TEXT_RETRY);
            };

            socket.onerror = (error) => {
                console.log('WebSocket text error:', error);
                socket.close();
            };
        }

        // Update the text canvas with new messages
        function updateTextCanvas() {
            const canvas = textMesh.material.map.image;
            const context = canvas.getContext('2d');
            context.clearRect(0, 0, canvas.width, canvas.height);
            context.font = `bold ${FONT_SIZE}px ${FONT_FAMILY}`;
            context.textAlign = 'left';

            let currentY = TEXT_OFFSET;
            let visibleText = [];

            // Implement word wrapping
            for (let i = 0; i < textBuffer.length; i++) {
                let words = textBuffer[i].split(' ');
                let currentLine = '';

                words.forEach(word => {
                    let testLine = currentLine + word + ' ';
                    let testWidth = context.measureText(testLine).width;

                    if (testWidth > MAX_TEXT_WIDTH && currentLine !== '') {
                        visibleText.push(currentLine);
                        currentLine = word + ' ';
                    } else {
                        currentLine = testLine;
                    }
                });

                visibleText.push(currentLine);
            }

            while ((visibleText.length * LINE_HEIGHT) > (canvas.height - TEXT_OFFSET)) {
                visibleText.shift();
            }

            visibleText.forEach((line, index) => {
                let alpha = 1;
                if (currentY < FADE_HEIGHT) {
                    alpha = Math.max((currentY / FADE_HEIGHT), 0);
                }

                context.fillStyle = `rgba(255, 255, 255, ${alpha})`;
                context.fillText(line, 20, currentY);
                currentY += LINE_HEIGHT;
            });

            textMesh.material.map.needsUpdate = true;
        }

        // ---------------------------------------------------------------------------
        // Event handlers
        // ---------------------------------------------------------------------------
        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function onDocumentMouseMove(event) {
            mouse.x = (event.clientX - window.innerWidth / 2) * 8;
            mouse.y = (event.clientY - window.innerHeight / 2) * 8;
            targetCameraPosition.set(mouse.x, -mouse.y, camera.position.z);
        }

        function onDocumentMouseLeave(event) {
            targetCameraPosition.copy(initialCameraPosition);
        }

        function onDocumentMouseWheel(event) {
            camera.position.z += event.deltaY * 0.5;
        }

        function onDocumentTouchStart(event) {
            if (event.touches.length === 1) {
                mouse.x = (event.touches[0].clientX - window.innerWidth / 2) * 8;
                mouse.y = (event.touches[0].clientY - window.innerHeight / 2) * 8;
                targetCameraPosition.set(mouse.x, -mouse.y, camera.position.z);
            }
        }

        function onDocumentTouchMove(event) {
            if (event.touches.length === 1) {
                mouse.x = (event.touches[0].clientX - window.innerWidth / 2) * 8;
                mouse.y = (event.touches[0].clientY - window.innerHeight / 2) * 8;
                targetCameraPosition.set(mouse.x, -mouse.y, camera.position.z);
            }
        }
    </script>
</body>
</html>
