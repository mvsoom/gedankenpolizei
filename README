# SEER 1

## TODO

### `seer.narrate`

- Fix seer.narrate.frame, seriously
- Implement --json switch in `seer.stream` to output json lines for metadata consumption
  * This can also power a --replay mode where the json is used to simulate the ~~descriptions~~narrations being fed to the thoughts stream
- Set NARRATE_TILE_NUM_FRAMES higher. WARNING: turn off stop sequence "</narration>" to see if the model understands NARRATE_TILE_NUM_FRAMES > 1 -- otherwise it will describe each frame within the til
- Make a "PLUMBING" log level that is lower than DEBUG for logging API messages etc. Also make a second log file that always records everything

## Latency issues

Latency can vary depending on the world's use of the API as much as 3x.

Knobs:

1. Smaller Claude model
2. Smaller image
3. Smaller memory bank size (# of previous images)

Quick latency (in sec) testing with a single sentence per tile, one frame per tile of size (640, 480):

- HAIKU:
  1.52, 1.55, 1.56, 1.61, 1.90, 2.00, 2.21, 2.70
- SONNET:
  2.36, 2.29, 2.58, 3.56, 3.26, 3.37, 3.49, 3.76
- OPUS:
  4.26, 3.93, 5.25, 5.17, 5.78, 7.53

The only other function that takes considerable time is the encode to PNG in order to send it to Claude, which is at most 0.1 sec.

These latencies include Python and Internet overhead. The computation (model) latencies can be checked at https://console.anthropic.com/settings/logs and are O(0.5) sec lower than the estimates above

## Cost issues

We could control for cost rather than latency. Lower latency = higher cost. Costs are dominated by the number of images and their size.

## Visualization

ASCII
- https://medium.com/@restlessladder/creating-cool-ascii-animation-and-watching-in-the-terminal-56f1c46ee35a
- mplayer -fs -vo caca tv:// -tv driver=v4l2:device=/dev/video0
  * https://forums.raspberrypi.com/viewtopic.php?t=252812