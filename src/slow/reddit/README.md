# Training an LLM on reddit data

## List of MLLMs

Sources:
  - Caffagni2024: DONE
  - https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models
  - https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding

### Quality Image LLMs

https://github.com/haotian-liu/LLaVA [BASELINE, demo]
https://github.com/mapluisch/LLaVA-CLI-with-multiple-images [code for putting images in a grid]

https://github.com/thunlp/LLaVA-UHD [no weights released yet]
https://github.com/OpenBMB/MiniCPM-V/blob/main/README_en.md [LOW PERFORMANCE, with weights, only 2B params]
  - This uses same technique as LLaVA-UHD and can process 6x6 grids of 336x336 px
  - Quite low performance when tested, but could be finetuned to achieve that
  - Very fast generation
  - More powerful variant: OmniLMM-12B (demo doesn't work)


https://github.com/InternLM/InternLM-XComposer [with demo] [with weights]


#### LLaVA

LLaVA also finetunes the LLM during training [https://github.com/haotian-liu/LLaVA/issues/577#issuecomment-1786201489]

```
Init
LLM: Vicuna
proj: None

Pretrain:
LLM: Vicuna
proj: llava-pretrain

Instruction tuning (resulting model: LLaVA-1.5)
LLM: Vicuna-llava-finetune
proj: llava-pretrain-llava-finetune

Task-specific finetuning (resulting model: finetuned LLaVA-1.5)
LLM: Vicuna-llava-finetune-task-finetune
proj: llava-pretrain-llava-finetune-task-finetune
```

Use custom finetuned LLM as base: https://github.com/haotian-liu/LLaVA/issues/520#issuecomment-1758740389 [seems implausible to work]


### Quality Video-LLMs

Promising => Time-aware: Use individual frames as memories
https://github.com/RenShuhuai-Andy/TimeChat [local demo] [weights]
  - Can run on A100 40 gb: 1$ / hr on brev.dev
  - Lower VRAM: https://github.com/RenShuhuai-Andy/TimeChat/issues/13


https://github.com/boheumd/MA-LMM [no demo] [promising] 

https://github.com/mbzuai-oryx/Video-LLaVA aka. PG-Video-LLaVA [no demo] [also uses audio] [with weights] [setup not trivial] [promising?]

https://github.com/dvlab-research/LLaMA-VID [no demo] [very long vids supported] [no multi image inference]

https://github.com/mbzuai-oryx/Video-ChatGPT [no demo] [annoying to setup]



### Summarizing frames

Given a set of frames of a movement, pick the most relevant one for retaining as a memory for the description. Possible methods:

- Average: creates blurry picture
- Find closest frame to description using ImageBind
- Ask the LLM to output it



### Prompting

"Most likely change that happened?"



## Directly training a VLLM

- Use Claude to describe stills coherently, (3 sec apart) x (max 20 images) = 1 min long videos
- Second pass: turn these descriptions into first person observations
- Third pass: Turn observations into Reddit-like thoughts
  * finetune Mistral to do this based on inverted training data generated by claude, turning reddit posts into dry pose
- Now we have training data = (posts x Reddit-like thoughts)
- Finetune a VLLM (visual LLM) on this


## Alternative: merging

We can merge our VLLM with our Reddit Mistral to transfer knowledge ... perhapse also style?

See mergekit

### Appropriate VLLMs

Appropriate = multiple images and qLora amenable

Almost all VLLMs can only handle one image.
However, image concatenation could be a very good option for videostills:
https://github.com/mapluisch/LLaVA-CLI-with-multiple-images

Options:
- Qwen-VL-chat: good, sizes from 0.5 to 72b parameters
- CogVLM: not good, multiple image not well understood per the arxiv paper
-  mPLUG-Owl: same as CogVLM

Other VLLMs based on good Bing chat:

PandaGPT1: PandaGPT can take multimodal inputs simultaneously and compose their semantics naturally12. However, it’s not explicitly mentioned if it supports multiple images.
MiniGPT43: There was a discussion on GitHub about MiniGPT4’s support for multiple images3. It seems that MiniGPT4 does not natively support multiple images, but there was a pull request to enable this feature3.
InstructBLIP4: Based on an inquiry on GitHub, it appears that InstructBLIP may not currently support multiple images4.
LLaMA-AdapterV25: The information available does not explicitly mention whether LLaMA-AdapterV2 supports multiple images5.
mPLUG-Owl678: mPLUG-Owl is designed to support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration678. It’s also mentioned that mPLUG-Owl has some unexpected abilities such as multi-image correlation67.
LLaVA9: As you mentioned, LLaVA does not support multiple images in their prompt. (https://github.com/haotian-liu/LLaVA/issues/824)
Qwen-VL-Chat1011129: Qwen-VL-Chat supports more flexible interaction, such as multiple image inputs, multi-round question answering, and creative capabilities1011129.

## PLAN

- Check Mistral finetuning (raw data) on brev.dev to see if it runs with **unsloth** mistral finetuning: DONE: nogo, unsloth too unstable (chheck issues)
- Use these LoRA settings to do Mistral finetuning for seq classification
- Trciky bits: Adapt Lucas' medium post for correct padding and end of sentence tokens etc. Should be exactly the same. Use identical lora config here. See notebook on Peters pc
- Lora optimization: https://huggingface.co/docs/peft/main/en/conceptual_guides/lora#initialization-options
- continuing from Lora checkpoint: https://github.com/huggingface/peft/issues/593 (still needs to switch head)
  => can first merge model (https://huggingface.co/docs/peft/main/en/conceptual_guides/lora#initialization-options) (this creates errors due to quantization so some information is lost) and then do another LoRA on top


## Hack: CSFT

> CSFT: **Conditional SFT (supervised finetuning)** is a simple alignment method
where a control token is prepended to the output during
training; then, at inference, the control token corre-
sponding to desirable generations (e.g., <|good|>) is
appended to the input to induce good generations (Kor-
bak et al., 2023). This is a non-HALO loss.

Prepend training data with new tokens <|good|>, <|bad|> etc. and then condition on inference time

Appears to Work very well in general (Korbak2023) and equally well as KTO on 7b scale (Fig 3 in Ethayarajh2024). It seems KTO is only better at larger scales

We can also use this to learn moods and guide mood in inference
For example "<|good|><|happy|>\nI see a man in front of me."
And so forth

Note: <|good|>/<|bad|> label must always come first such that the model is free to predict <|happy|> label after it

### Challenges

- **Adding new tokens with qLora**

This is possible (though there are some quirks to be aware of): see this notebook: https://www.kaggle.com/code/aisuko/fine-tuning-mistral-with-qlora, it will probably work out of the box

Increases # of parameters strongly since embedding and output and others must be trained

Finding resources on this is quite difficult. Here they are, ranked from best to worst:
- https://www.kaggle.com/code/aisuko/fine-tuning-mistral-with-qlora (already given)
- https://github.com/huggingface/peft/issues/334 leading to https://colab.research.google.com/drive/16qKy92cGoNPWrlQ4zlvntVGeSgjrknVF?usp=sharing#scrollTo=LTtSABGVOQSK
- https://discuss.huggingface.co/t/qlora-llama2-additional-special-tokens/50121
- https://www.reddit.com/r/LocalLLaMA/comments/17s3jkd/comment/k8rn1op/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button

- **Data imbalance**

Much less examples of <|good|> than bad -- KTO can handle this, not sure if we can

+ **Can simply reuse script, no new trainer/hyperparamaters needed**

Unlike KTO, which uses a new trainer


## First finetuning with Qlora, then polishing with KTO

ORPO and DPO use for data = { prompt, accepted completion, rejected completion }

But we have just good and bad examples, for which no of bad examples are far more
So need to KTO: specifically made for this! See its arxiv paper

Can be combined with qlora: https://github.com/huggingface/trl/blob/main/examples/scripts/kto.py

so this is the way to go, only need to figure out how to get rid of chat template

"https://arxiv.org/html/2402.01306v1"

> KTO **can handle extreme data imbalances**, matching DPO performance while using up to 90% fewer desirable examples (i.e., examples of good generations). Its success thus cannot be ascribed to the alignment data being sourced from a preference dataset.
> When the pretrained model is sufficiently good, **one can skip supervised finetuning and go straight to KTO** without a loss in generation quality. In contrast, we find that without doing SFT first, DPO-aligned models are significantly worse at all scales.


## Incorporating negative examples: = model alignment/preference alignment
https://news.ycombinator.com/item?id=39934480

> If you do end up wanting to fine tune then use qlora with axolotl or unsloth to prove your hypothesis on a smaller model and then evaluate if you want the marginal gains you get from full precision training.

> After you fine tune it with 100m token dataset, **use DPO to polish it off** [we use KTO]. You need to create a DPO dataset for that but it can be relatively small to get some great gains.

> This is great advice!
> I'd like to add that if you don't have pairwise preference data (A > B) but do have binary data (A is good for x_1, B is good for x_2, etc.), then **Kahneman-Tversky Optimization (KTO) might be a better fit.** Despite learning with a weaker signal, it works as well or better than dpo in practice.

[I checked the guy who commented this and he is very lit so ok to trust]

## TODO

- Complete HF NLP course
  Data collator: https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt#processing-the-data
- NER pipeline for labeling
- See if dude answered comment on Medium
- Check if Mistral finetuning uses same LoRA components: https://medium.com/@codersama/fine-tuning-mistral-7b-in-google-colab-with-qlora-complete-guide-60e12d437cca : yes, same models, only 'gate_proj' differed -- in general use ALL linear layers
  https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb
- See Andrej Karpathy YT videos


## "Merging Loras"

Using LoRAs sequentiall can be done by using add_weighted_adapter() since LoRAs are just summed to the frozen linear layers -- see
https://stackoverflow.com/questions/77491934/is-this-right-way-to-merge-lora-weights


## Grounding (Giving instructions): possibilities

Prepend "prompt" in the vein of: "I am a camera hanging (etc.)"

Generate synthetic training data about it being a camera

## Seeding

Reading the daily newspaper?

## Sequence classification

into good and bad posts:

https://medium.com/@lukas.hauzenberger/multilabel-classification-using-mistral-7b-on-a-single-gpu-with-quantization-and-lora-8f848b5237f3

The training done in this tutorial is ~24 hrs for 10 epochs (30k training rows)


combine with unsloth: https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth

  Training Mistral on text completion of stories:
  https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing

note mistral better than gemma

can also use BERT for classification if we cant reuse LoRAs (reddit question): https://www.reddit.com/r/LocalLLaMA/comments/1afgibb/experience_replacing_gpt4_with_bert_for/

can we reuse mistral 7b then? -- yes, it seems so: the classificaton (linear) layer is added after the last layer before converting to a prob distribution over next token. in this way we can use the negative posts when finetuning further to predict SOCs: a good initial guess for further LoRA training

https://stackoverflow.com/questions/69907682/what-are-differences-between-automodelforsequenceclassification-vs-automodel

![Alt text](assets/automodel.png)

Concatenate posts by the same author sorted by date to get longer training sequences!


## GPUs

runpods.io:
- cheap,
- notebooks,
- [yes API deployment](https://github.com/runpod-workers/worker-template),
- streaming
- yes persistent storage

lambdalabs:
- cheaper,
- notebooks,
- NO API deployment
- ~0.75 dollar/hour

serve on HuggingFace?



TIP:
upload & download data/(finetuned) models to Huggingface: faster speeds


## Training data

concatenate posts following each other by embedding them to get a long text a la phi 1.5
so two posts follow each other when they have the closest embedding

use the classifier to find any SOC-like text, eg in a novel

## other

- headphones with TTS, maybe in Microsoft SAM voice or The Expressionless voice
- generate images based on SOC for training data8
- zie whatsapp anton

## Datasets

- [x] [1m confessions](https://www.kaggle.com/datasets/pavellexyr/one-million-reddit-confessions/data): Looks good, downloaded zip file
- [x] [convokit-reddit](https://convokit.cornell.edu/documentation/subreddit.html): Looks good, downloadable via Python API
- [?] [tf-reddit](https://www.tensorflow.org/datasets/catalog/reddit): Could be good; untested
- [/] [reddit self-post](https://www.kaggle.com/datasets/mswarbrickjones/reddit-selfposts): Bad choice of subreddits for our purposes ... but good notebooks on Kaggle
- [/] [reddit 2014 graph](https://paperswithcode.com/dataset/reddit): Unusuable
- [/] [webis/tldr-17](https://huggingface.co/datasets/webis/tldr-17): Bad choice of subreddits for our purposes ... but good for summarization (metathoughts)
- [?] [Reddit comments/submissions 2005-06 to 2023-12](https://academictorrents.com/details/9c263fc85366c1ef8f5bb9da0203f4c8c8db75f4): Full scrape, 2 TB.
  - [More of these](https://academictorrents.com/browse.php?search=stuck_in_the_matrix)
  - [API service to query this data](https://www.pullpush.io/): Very good but site is unstable

## Good subreddits...

... are those containing posts with a stream-of-consciousness (SOC) feel.

Good starting point is 
- [x] https://www.reddit.com/r/letters/

From there, see related subreddits of r/letters at https://anvaka.github.io/map-of-reddit/?x=23033.519670875172&y=19494.765659988872&z=50&v=2&q=letters:

- https://www.reddit.com/r/LoveLetters/
- https://www.reddit.com/r/unsent/
- [x] https://www.reddit.com/r/Diary/ => very good
- [ ] https://www.reddit.com/r/LibraryofBabel/ => funky, tasteful noise
- [ ] https://www.reddit.com/r/LibraryofBabel/ => funky, tasteful noise
- https://www.reddit.com/r/ShrugLifeSyndicate/ => weird noise

Other gems:

- [ ] https://www.reddit.com/r/venting/
- [x] https://www.reddit.com/r/self/

python scrape.py Life subreddit/Life.csv --maxfsize 10 --verbose

### Original subreddits

DeepThoughts
Diary
Informal_Effect
letters
LibraryofBabel
Life
meaningoflife
self
ShittyPoetry
UnsentNotes
venting

### New subreddits

Mindfulness
Antinatalism
unpopularopinion
sociopath
NPD
Ange
MaladaptiveDreaming
Dissociation
misanthropy
nihilism
Existential_crisis
ForeverAlone

### Also: 2sentence subreddits

Always has <[TITLE] ONESENTENCE> form ... to learn connection

## Other

Create character personalities
- by grouping semantically similar reddit posts such as happy, narcicistix, etc, and training on thay

Memories
- fresh seeding from RAG in our reddit db, so finding semanticallt similar thoughts to the current ones (in current soc)
- get interesting thought seeds from https://www.kaggle.com/datasets/a24998667/reddit-showerthoughts-corpus

Camera-like posts
- finding posts by vector search for "I see" etc

Post lenths
- posts are already structured as single thoughts! And have good lengths. And have meta title
- are good building blocks

We can use the post titles as seed/summaries/...! In the training data we could for example use them as metathoughts

Comments
- could be good meta thoughts too

Leapfrog idea:
-  go from title to content to title to content ... where the content contains camera descriptions and only title predictions are shown (short thoughts) ... and the predicted content given title then serves as a "lower level metathought" which seeds the next "surface thought"

## Detection of movement

- with simple energy measure and mfbod (mckay basian online detection)
- if burst of movement, then inject description

## Ideas

Rewrite posts using an LLM; could also be good for copyright

https://kaitchup.substack.com/p/phi-2-a-small-model-easy-to-fine

contrastive learning

Semi-supervised learning: A small amount of data that is correctly labeled data is used with large unlabeled data. The model makes predictions on the unlabeled data and where it is very sure, those samples are added to the next iteration of model training. It’s an iterative process in which models keep getting better with more and more trained data

Triple loss

https://huggingface.co/blog/Andyrasika/finetune-unsloth-qlora


## Integrating stream in 3D
Piping ffmpeg into the 3D engine is not directly possible in unreal or unity it seems

But we can hack it by having ffmpeg pipe the output as if it is a webcam

https://superuser.com/questions/411897/using-desktop-as-fake-webcam-on-linux

Then:

https://docs.unrealengine.com/4.27/en-US/WorkingWithMedia/IntegratingMedia/MediaFramework/HowTo/UsingWebCams/

https://docs.unity3d.com/ScriptReference/WebCamTexture.html

or better to use webgl:

https://medium.com/docler-engineering/webgl-video-manipulation-8d0892b565b6


## Resources

- https://www.reddit.com/r/LocalLLaMA/comments/17j1zcw/best_way_to_finetune_llm_based_on_daily_journals/
- https://www.reddit.com/r/LocalLLaMA/comments/190xnij/can_a_rag_in_conjunction_with_an_llm_create_a/

## Other random ideas

- whatsapp (qr code or text to nuber). start slow and then spam
- coat the sculpture with sugar and make it covered with flies,worms,bees